{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "global l\n",
    "l = []\n",
    "\n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLeftNav(url):\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "\n",
    "    # Scrap\n",
    "    i1 = soup.find_all('td', {\"id\": \"leftnav\"})\n",
    "    i2 = i1[0].find_all('ul')\n",
    "    i3 = [i.find_all('li') for i in i2]\n",
    "\n",
    "    try:\n",
    "        if 'Effacer' in str(i3[len(i3) - 1][1]):\n",
    "            i3 = i3[0:len(i3) - 1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    d = {}\n",
    "    d2 = {}\n",
    "\n",
    "    # Filling of the 2 dictionaries \n",
    "    for j in range(1, len(i3)):\n",
    "        i4 = [i.find_all('a') for i in i3[j]]\n",
    "        p = re.compile('(?<=\\\")(.*?)(?=\\\")')\n",
    "        k = [p.findall(str(i)) for i in i4]\n",
    "        k = k[1:len(k)]\n",
    "        i5 = [i.text for i in i3[j]]\n",
    "        key = i5[0]\n",
    "        values = i5[1:]\n",
    "        values = [i.replace('\\xa0', ' ') for i in values]\n",
    "        values = [i for i in values if i not in 'Effacer']\n",
    "\n",
    "        for e in range(len(values)):\n",
    "            try:\n",
    "                url = 'https://www.google.com' + k[e][0].replace('&amp;', '&')\n",
    "                d2[values[e]] = url\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        d[key] = values\n",
    "\n",
    "    return soup, d, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visu(soup):\n",
    "    j1 = soup.find_all('div', {'class': 'g'})\n",
    "    j2 = [j.find_all('div', {'class': 'pslires'}) for j in j1]\n",
    "\n",
    "    data = {'Name': [], 'Preco': [], 'Loja': [], 'Descrição': []}\n",
    "\n",
    "    for i in range(len(j2)):\n",
    "        try:\n",
    "            name = j2[i][0].find_all('a')[1].text\n",
    "            data['Name'].append(name)\n",
    "        except:\n",
    "            data['Name'].append('none')\n",
    "\n",
    "        try:\n",
    "            price = j2[i][0].find_all('div')[2].text.replace('\\xa0', ' ')\n",
    "            reta = j2[i][0].find_all('div')[3].text.replace('\\xa0', ' ')\n",
    "            data['Preco'].append(price)\n",
    "            data['Loja'].append(reta)\n",
    "        except:\n",
    "            data['Preco'].append('none')\n",
    "            data['Loja'].append('none')\n",
    "\n",
    "        try:\n",
    "            desc = j2[i][0].find_all('div')[5].text\n",
    "            data['Descrição'].append(desc)\n",
    "        except:\n",
    "            data['Descrição'].append('none')\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_vl(vals, param):\n",
    "    if 'R$' in vals and '–' in vals:\n",
    "        lista = vals.replace('R$', '').replace(' ', '').replace('.', '').\\\n",
    "            replace(',', '.').split('–')\n",
    "\n",
    "        if len(lista) > 1:\n",
    "            if float(lista[0]) >= param['de'] and \\\n",
    "                    float(lista[1]) <= param['ate']:\n",
    "                return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_vl(d2, param):\n",
    "    fil_vl = [d2[k] for k in d2.keys() if val_vl(vals=k, param=param)]\n",
    "\n",
    "    return fil_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_param(val, param_key, param):\n",
    "    if param_key in val:\n",
    "        if param[param_key]['tipo'] == 'int':\n",
    "            res = int(re.findall('\\d+', val)[0])\n",
    "            if param[param_key]['de'] <= res <= param[param_key]['ate']:\n",
    "                return True\n",
    "        if param[param_key]['tipo'] == 'str':\n",
    "            return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_param(d2, param):\n",
    "    fil_p = [d2[k] for k in d2.keys()\n",
    "             if val_param(val=k, param_key=p, param=param)]\n",
    "\n",
    "    return fil_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = 'Geladeira'\n",
    "url_master = 'https://www.google.com/search?q=' + req + \\\n",
    "             '&source=lnms&tbm=shop&start=0'\n",
    "\n",
    "param = {'valor': {'de': 1000, 'ate': 2000},\n",
    "         'param': {'litros': {'tipo': 'int', 'de': 300, 'ate': 500},\n",
    "                   'frost free': {'tipo': 'str', 'de': '', 'ate': ''},\n",
    "                   'duplex': {'tipo': 'str', 'de': '', 'ate': ''},\n",
    "                   'inox': {'tipo': 'str', 'de': '', 'ate': ''}, }}\n",
    "\n",
    "soup, d, d2 = getLeftNav(url_master)\n",
    "\n",
    "url_filtro_vls = filtro_vl(d2, param=param['valor'])\n",
    "\n",
    "url_filtros = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in url_filtro_vls:\n",
    "    soup, d, d2 = getLeftNav(url)\n",
    "    for p in param['param']:\n",
    "        for u in filtro_param(d2=d2, param=p):\n",
    "            print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
